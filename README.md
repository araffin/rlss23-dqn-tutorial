# Reinforcement Learning Summer School 2023 - DQN Tutorial

<img style="background:white;" src="https://araffin.github.io/slides/dqn-tutorial/images/q_learning/dqn_pirate_cover.png" align="right" width="40%"/>

## From Tabular Q-Learning to DQN

Blog post: https://araffin.github.io/post/rl102/

Website: https://rlsummerschool.com/

Slides: https://araffin.github.io/slides/dqn-tutorial/

Stable-Baselines3 repo: https://github.com/DLR-RM/stable-baselines3

RL Virtual School 2021: https://github.com/araffin/rl-handson-rlvs21

<img style="background:white;" src="https://araffin.github.io/slides/dqn-tutorial/images/dqn/dqn.png" align="center" width="80%"/>

## Content

1. Fitted Q-Iteration (FQI) [Colab Notebook](https://colab.research.google.com/github/araffin/rlss23-dqn-tutorial/blob/main/notebooks/1_fitted_q_iteration_fqi.ipynb)
2. Deep Q-Network (DQN) Part I: DQN Components: Replay Buffer, Q-Network, ... [Colab Notebook](https://colab.research.google.com/github/araffin/rlss23-dqn-tutorial/blob/main/notebooks/2_deep_q_network_dqn_components.ipynb)
3. Deep Q-Network (DQN) Part II: DQN Update and Training Loop [Colab Notebook](https://colab.research.google.com/github/araffin/rlss23-dqn-tutorial/blob/main/notebooks/3_deep_q_network_dqn_update.ipynb)

## Solutions

Solutions can be found in the [notebooks/solutions/](https://github.com/araffin/rlss23-dqn-tutorial/tree/main/notebooks/solutions) folder.
The code in `dqn_tutorial` package can also be used to bypass some exercises.
